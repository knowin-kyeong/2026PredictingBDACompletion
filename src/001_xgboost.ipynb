{"cells":[{"cell_type":"markdown","metadata":{"id":"nTDDIhakCdiR"},"source":["만약 Colab environment인 경우 다음과 같은 코드 실행"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17464,"status":"ok","timestamp":1771913548574,"user":{"displayName":"서주원","userId":"14333494995005266195"},"user_tz":-540},"id":"TMN6yx5ZBngl","outputId":"83de3716-26f7-4ad2-9d7c-4a33596f50fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir('/content/drive/MyDrive/2026PredictingBDACompletion/src')"]},{"cell_type":"markdown","metadata":{"id":"9AjGA8kiCrH0"},"source":["Local environment의 경우 cd 명령어를 사용하여 working directory 조정\n","\n","최종적으로, 다음 코드 조각이 이 파일이 속한 디렉토리를 지시해야 함"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1771913548589,"user":{"displayName":"서주원","userId":"14333494995005266195"},"user_tz":-540},"id":"W8vZnCWpCjkr","outputId":"75093fdf-f91b-43ea-9a14-40041edff33b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/2026PredictingBDACompletion/src\n"]}],"source":["print(os.getcwd())"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":91865,"status":"ok","timestamp":1771913640456,"user":{"displayName":"서주원","userId":"14333494995005266195"},"user_tz":-540},"id":"YrIfPjUJAZYc","outputId":"8f23a2cd-bada-4f28-acf3-f99be9246249"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy==2.0.2 in /usr/local/lib/python3.12/dist-packages (from -r ../requirements.txt (line 1)) (2.0.2)\n","Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.12/dist-packages (from -r ../requirements.txt (line 2)) (2.2.2)\n","Requirement already satisfied: scikit-learn==1.6.1 in /usr/local/lib/python3.12/dist-packages (from -r ../requirements.txt (line 3)) (1.6.1)\n","Requirement already satisfied: scipy==1.16.3 in /usr/local/lib/python3.12/dist-packages (from -r ../requirements.txt (line 4)) (1.16.3)\n","Collecting catboost==1.2.8 (from -r ../requirements.txt (line 5))\n","  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Collecting torch==2.9.0 (from -r ../requirements.txt (line 6))\n","  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n","Collecting optuna==4.6.0 (from -r ../requirements.txt (line 7))\n","  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n","Collecting tqdm==4.67.1 (from -r ../requirements.txt (line 8))\n","  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->-r ../requirements.txt (line 2)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->-r ../requirements.txt (line 2)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->-r ../requirements.txt (line 2)) (2025.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.6.1->-r ../requirements.txt (line 3)) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.6.1->-r ../requirements.txt (line 3)) (3.6.0)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost==1.2.8->-r ../requirements.txt (line 5)) (0.21)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost==1.2.8->-r ../requirements.txt (line 5)) (3.10.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost==1.2.8->-r ../requirements.txt (line 5)) (5.24.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost==1.2.8->-r ../requirements.txt (line 5)) (1.17.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (3.24.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (2.27.5)\n","Collecting nvidia-nvshmem-cu12==3.3.20 (from torch==2.9.0->-r ../requirements.txt (line 6))\n","  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->-r ../requirements.txt (line 6)) (1.13.1.3)\n","Collecting triton==3.5.0 (from torch==2.9.0->-r ../requirements.txt (line 6))\n","  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna==4.6.0->-r ../requirements.txt (line 7)) (1.18.4)\n","Collecting colorlog (from optuna==4.6.0->-r ../requirements.txt (line 7))\n","  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna==4.6.0->-r ../requirements.txt (line 7)) (26.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna==4.6.0->-r ../requirements.txt (line 7)) (2.0.46)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna==4.6.0->-r ../requirements.txt (line 7)) (6.0.3)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna==4.6.0->-r ../requirements.txt (line 7)) (1.3.10)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna==4.6.0->-r ../requirements.txt (line 7)) (3.3.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->-r ../requirements.txt (line 6)) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->-r ../requirements.txt (line 6)) (3.0.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost==1.2.8->-r ../requirements.txt (line 5)) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost==1.2.8->-r ../requirements.txt (line 5)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost==1.2.8->-r ../requirements.txt (line 5)) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost==1.2.8->-r ../requirements.txt (line 5)) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost==1.2.8->-r ../requirements.txt (line 5)) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost==1.2.8->-r ../requirements.txt (line 5)) (3.3.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost==1.2.8->-r ../requirements.txt (line 5)) (9.1.4)\n","Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading optuna-4.6.0-py3-none-any.whl (404 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n","Installing collected packages: triton, tqdm, nvidia-nvshmem-cu12, colorlog, torch, optuna, catboost\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.6.0\n","    Uninstalling triton-3.6.0:\n","      Successfully uninstalled triton-3.6.0\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.67.3\n","    Uninstalling tqdm-4.67.3:\n","      Successfully uninstalled tqdm-4.67.3\n","  Attempting uninstall: nvidia-nvshmem-cu12\n","    Found existing installation: nvidia-nvshmem-cu12 3.4.5\n","    Uninstalling nvidia-nvshmem-cu12-3.4.5:\n","      Successfully uninstalled nvidia-nvshmem-cu12-3.4.5\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.10.0+cu128\n","    Uninstalling torch-2.10.0+cu128:\n","      Successfully uninstalled torch-2.10.0+cu128\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.10.0+cu128 requires torch==2.10.0, but you have torch 2.9.0 which is incompatible.\n","torchvision 0.25.0+cu128 requires torch==2.10.0, but you have torch 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed catboost-1.2.8 colorlog-6.10.1 nvidia-nvshmem-cu12-3.3.20 optuna-4.6.0 torch-2.9.0 tqdm-4.67.1 triton-3.5.0\n"]}],"source":["!pip install -r ../requirements.txt"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUdGhnaQvh1q","executionInfo":{"status":"ok","timestamp":1771913695363,"user_tz":-540,"elapsed":54903,"user":{"displayName":"서주원","userId":"14333494995005266195"}},"outputId":"52e2322b-ea03-4aed-a56f-6541bbace3d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Dataset] Trying to load all files from ../data\n","[Dataset] All data loaded successfully from ../data\n","\n","[Pre-Processing] Applying FE...\n","[Encoding] Fitting LE on Train ONLY...\n","[Pre-Processing] 50 features prepared.\n","\n","[Info] Current Mode is Load\n","\n","[Load] Load Previous Best Params: {'n_estimators': 1455, 'learning_rate': 0.01581233636756958, 'max_depth': 4, 'min_child_weight': 8, 'gamma': 1.8554367882106972, 'subsample': 0.5178143107493339, 'colsample_bytree': 0.7705593029127545, 'reg_alpha': 0.15001414550285752, 'reg_lambda': 0.11106665752617169, 'scale_pos_weight': 1.5086109724471912}\n","[Train] XGBoost with Seed Ensemble\n","[Seed 42] Best F1: 0.4645 @ 0.369\n","[Seed 142] Best F1: 0.4838 @ 0.307\n","[Seed 242] Best F1: 0.4766 @ 0.269\n","[Seed 342] Best F1: 0.4753 @ 0.347\n","[Seed 442] Best F1: 0.4776 @ 0.281\n","[Seed 542] Best F1: 0.4625 @ 0.279\n","[Seed 642] Best F1: 0.4715 @ 0.258\n","[Seed 742] Best F1: 0.4610 @ 0.218\n","[Seed 842] Best F1: 0.4809 @ 0.315\n","[Seed 942] Best F1: 0.4806 @ 0.334\n","\n","[Post-Processing] Threshold will be override to 0.351\n","\n","[Result] Saved: ../outputs/submission_xgboost.csv\n"]}],"source":["import json\n","import os\n","import random\n","import sys\n","from datetime import datetime\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","import optuna\n","from optuna.samplers import TPESampler\n","from sklearn.metrics import f1_score, log_loss\n","from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\n","import xgboost as xgb\n","import torch\n","\n","# =======================\n","# CONFIG\n","# =======================\n","BASE_DIR = Path(\"..\")\n","DATA_DIR = BASE_DIR / \"data\"\n","OUTPUT_DIR = BASE_DIR / \"outputs\"\n","OUTPUT_DIR.mkdir(exist_ok=True)\n","OUTPUT_PATH = OUTPUT_DIR / \"submission_xgboost.csv\"\n","\n","GLOBAL_SEED = 42\n","\n","TARGET_COL = \"completed\"\n","ID_COL = \"ID\"\n","\n","GROUP_COLS = [\"school1\"]\n","GROUP_KEY_NAME = \"group__school1\"\n","\n","FORCE_CAT_COLS = [\"school1\", \"class1\", \"class2\", \"class3\", \"class4\"]\n","\n","MANUAL_TEXT_COLS = [\n","    \"whyBDA\", \"what_to_gain\", \"incumbents_lecture\",\n","    \"certificate_acquisition\", \"incumbents_lecture_scale_reason\", \"onedayclass_topic\"\n","]\n","\n","N_SPLITS = 5\n","\n","MODE = 'Load'\n","OPTUNA_SEED = 42\n","OPTUNA_TRIALS = 100\n","FINAL_TRAIN_SEEDS = [42, 142, 242, 342, 442, 542, 642, 742, 842, 942]\n","\n","# =======================\n","# REPRODUCIBILITY\n","# =======================\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n","\n","# =======================\n","# UTILS\n","# =======================\n","def find_best_threshold(y_true, prob, step=0.001):\n","    best_t, best_f1 = 0.5, -1.0\n","    for t in np.arange(0.1, 0.9, step):\n","        pred = (prob >= t).astype(int)\n","        f1 = f1_score(y_true, pred)\n","        if f1 > best_f1:\n","            best_f1, best_t = f1, t\n","    return float(best_t), float(best_f1)\n","\n","def make_submission_df(sample_sub, test_df, preds, id_col, target_col):\n","    ids = sample_sub[id_col].copy() if id_col in sample_sub.columns else test_df[id_col].copy()\n","    out = pd.DataFrame({id_col: ids})\n","    out[target_col] = preds\n","    return out\n","\n","def build_group_key(df: pd.DataFrame, cols, key_name: str) -> pd.Series:\n","    key = df[cols[0]].astype(\"string\").fillna(\"MISSING\")\n","    for c in cols[1:]:\n","        key = key + \"__\" + df[c].astype(\"string\").fillna(\"MISSING\")\n","    return key\n","\n","# =======================\n","# FE & ENCODING\n","# =======================\n","def apply_fe(df):\n","    # 1. IT Major\n","    keyword_regex = 'IT|정보|컴퓨터|소프트|인공지능|AI|데이터|SW|ICT'\n","    if 'major_field' in df.columns:\n","        df['is_it'] = df['major_field'].astype(str).str.contains(keyword_regex, case=False, na=False).astype(int)\n","\n","    # 2. Certificate\n","    if 'certificate_acquisition' in df.columns:\n","        df['cert_count'] = df['certificate_acquisition'].fillna(\"\").apply(lambda x: x.count(',') + 1 if x != \"\" else 0)\n","        df['has_adsp'] = df['certificate_acquisition'].fillna(\"\").str.contains('ADsP', case=False).astype(int)\n","        df['has_sqld'] = df['certificate_acquisition'].fillna(\"\").str.contains('SQLD', case=False).astype(int)\n","\n","    # 3. Job Keywords\n","    if 'desired_job_except_data' in df.columns:\n","        df['want_uiux'] = df['desired_job_except_data'].fillna(\"\").str.contains('UI|UX', case=False).astype(int)\n","        df['want_pm'] = df['desired_job_except_data'].fillna(\"\").str.contains('PM|기획', case=False).astype(int)\n","\n","    # 4. School\n","    if 'school1' in df.columns:\n","        df['is_school_0'] = (df['school1'] == 0).astype(int)\n","\n","    return df\n","\n","def clean_lecture(train, test):\n","    col = 'incumbents_lecture'\n","    if col in train.columns:\n","        top3 = train[col].value_counts().nlargest(3).index.tolist()\n","        def clean(x): return x if x in top3 else top3[0]\n","        train[col] = train[col].apply(clean)\n","        test[col] = test[col].apply(clean)\n","    return train, test\n","\n","def encode_categories(train, test):\n","    \"\"\"\n","    Fits LabelEncoder ONLY on Train data.\n","    Unseen labels in Test data are mapped to -1.\n","    \"\"\"\n","    # 1. Text columns -> Length features\n","    for c in MANUAL_TEXT_COLS:\n","        if c in train.columns:\n","            train[f'{c}_len'] = train[c].fillna(\"\").apply(len)\n","            test[f'{c}_len'] = test[c].fillna(\"\").apply(len)\n","            train = train.drop(columns=[c])\n","            test = test.drop(columns=[c])\n","\n","    # 2. Categorical columns -> Custom Label Encoding\n","    cat_cols = [c for c in train.columns if train[c].dtype == 'object']\n","\n","    for c in cat_cols:\n","        # Fill NA with specific string to treat it as a category\n","        train_vals = train[c].fillna(\"MISSING\").astype(str)\n","        test_vals = test[c].fillna(\"MISSING\").astype(str)\n","\n","        # Create mapping ONLY from Train unique values\n","        unique_train = train_vals.unique()\n","        mapping = {val: i for i, val in enumerate(unique_train)}\n","\n","        # Transform Train\n","        train[c] = train_vals.map(mapping)\n","\n","        # Transform Test (Map unknown values to -1)\n","        test[c] = test_vals.apply(lambda x: mapping.get(x, -1))\n","\n","        # Convert to int\n","        train[c] = train[c].astype(int)\n","        test[c] = test[c].astype(int)\n","\n","    return train, test\n","\n","# =======================\n","# OPTUNA\n","# =======================\n","def objective(trial, X, y, groups):\n","    params = {\n","        'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n","        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n","        'max_depth': trial.suggest_int('max_depth', 3, 10),\n","        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n","        'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n","        'subsample': trial.suggest_float('subsample', 0.5, 0.9),\n","        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9),\n","        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 10.0, log=True),\n","        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 10.0, log=True),\n","        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.5, 4.0),\n","\n","        'objective': 'binary:logistic',\n","        'eval_metric': 'logloss',\n","\n","        'tree_method': 'hist',\n","        'device': 'cuda',\n","\n","        'early_stopping_rounds': 50,\n","        'random_state': OPTUNA_SEED,\n","        'verbosity': 0\n","    }\n","\n","    scores = []\n","    seed_everything(OPTUNA_SEED)\n","\n","    cv = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=OPTUNA_SEED)\n","    splitter = cv.split(X, y, groups=groups)\n","\n","    for tr_idx, va_idx in splitter:\n","        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n","        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n","\n","        model = xgb.XGBClassifier(**params)\n","\n","        model.fit(\n","            X_tr, y_tr,\n","            eval_set=[(X_va, y_va)],\n","            verbose=False\n","        )\n","\n","        pred_proba = model.predict_proba(X_va)[:, 1]\n","        score_ll = log_loss(y_va, pred_proba)\n","        scores.append(score_ll)\n","\n","    return np.mean(scores)\n","\n","# =======================\n","# FINAL TRAIN\n","# =======================\n","def run_training(best_params, X, y, groups, X_test):\n","    print(\"[Train] XGBoost with Seed Ensemble\")\n","\n","    best_params.update({\n","        'objective': 'binary:logistic',\n","        'eval_metric': 'logloss',\n","        'tree_method': 'hist',\n","        'device': 'cuda',\n","        'verbosity': 0,\n","        'early_stopping_rounds': 100\n","    })\n","\n","    oof_preds = []\n","    test_preds = []\n","\n","    for seed in FINAL_TRAIN_SEEDS:\n","        seed_everything(seed)\n","        best_params['random_state'] = seed\n","\n","        oof = np.zeros(len(X))\n","        test_p = []\n","\n","        cv = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=seed)\n","        splitter = cv.split(X, y, groups=groups)\n","\n","        for tr, va in splitter:\n","            model = xgb.XGBClassifier(**best_params)\n","            model.fit(\n","                X.iloc[tr], y.iloc[tr],\n","                eval_set=[(X.iloc[va], y.iloc[va])],\n","                verbose=False\n","            )\n","\n","            oof[va] = model.predict_proba(X.iloc[va])[:, 1]\n","            test_p.append(model.predict_proba(X_test)[:, 1])\n","\n","        oof_preds.append(oof)\n","        test_preds.append(np.mean(test_p, axis=0))\n","\n","        best_t, best_f1 = find_best_threshold(y, oof, step=0.001)\n","        print(f\"[Seed {seed}] Best F1: {best_f1:.4f} @ {best_t:.3f}\")\n","\n","    ens_oof = np.mean(oof_preds, axis=0)\n","    ens_test = np.mean(test_preds, axis=0)\n","\n","    return ens_oof, ens_test\n","\n","# =======================\n","# MAIN\n","# =======================\n","def main():\n","    seed_everything(GLOBAL_SEED)\n","\n","    print(f\"[Dataset] Trying to load all files from {DATA_DIR}\")\n","\n","    train_path = DATA_DIR / \"train.csv\"\n","    if not train_path.exists():\n","        raise FileNotFoundError(f\"[Error] Dataset not found at {train_path}\")\n","        return\n","    else:\n","        try:\n","            train = pd.read_csv(train_path, encoding=\"utf-8-sig\")\n","        except:\n","            raise Exception(f\"[Error] Train dataset loading failed from {train_path}\")\n","            return\n","\n","    test_path = DATA_DIR / \"test.csv\"\n","    if not test_path.exists():\n","        raise FileNotFoundError(f\"[Error] Dataset not found at {test_path}\")\n","    else:\n","        try:\n","            test = pd.read_csv(test_path, encoding=\"utf-8-sig\")\n","        except:\n","            raise Exception(f\"[Error] Test dataset loading failed from {test_path}\")\n","            return\n","\n","    sub_path = DATA_DIR / \"sample_submission.csv\"\n","    if not sub_path.exists():\n","        raise FileNotFoundError(f\"[Error] Dataset not found at {sub_path}\")\n","        return\n","    else:\n","        try:\n","            sub = pd.read_csv(sub_path, encoding=\"utf-8-sig\")\n","        except:\n","            raise Exception(f\"[Error] Submission template loading failed from {sub_path}\")\n","            return\n","\n","    print(f\"[Dataset] All data loaded successfully from {DATA_DIR}\")\n","\n","    groups = build_group_key(train, GROUP_COLS, GROUP_KEY_NAME)\n","\n","    print(\"\\n[Pre-Processing] Applying FE...\")\n","    train = apply_fe(train)\n","    test = apply_fe(test)\n","    train, test = clean_lecture(train, test)\n","\n","    # Drop\n","    drops = [ID_COL, 'major_field', 'generation', 'incumbents_level', TARGET_COL]\n","    y = train[TARGET_COL].astype(int)\n","    X = train.drop(columns=drops, errors='ignore')\n","\n","    X_test = test.drop(columns=drops, errors='ignore')\n","    X_test = X_test.reindex(columns=X.columns, fill_value=np.nan)\n","\n","    # Nan Count & Log Time\n","    X['nan_count'] = X.isnull().sum(axis=1)\n","    X_test['nan_count'] = X_test.isnull().sum(axis=1)\n","    if 'time_input' in X.columns:\n","        X['log_time_input'] = np.log1p(pd.to_numeric(X['time_input'], errors='coerce').fillna(0))\n","        X_test['log_time_input'] = np.log1p(pd.to_numeric(X_test['time_input'], errors='coerce').fillna(0))\n","\n","    # Encoding\n","    print(\"[Encoding] Fitting LE on Train ONLY...\")\n","    X, X_test = encode_categories(X, X_test)\n","\n","    print(f\"[Pre-Processing] {X.shape[1]} features prepared.\")\n","\n","    print(f\"\\n[Info] Current Mode is {MODE}\")\n","\n","    if MODE == 'Tune':\n","        # Optuna\n","        print(\"\\n[Optuna] Tuning XGBoost (GPU)...\")\n","        optuna.logging.set_verbosity(optuna.logging.WARNING)\n","        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=GLOBAL_SEED))\n","        func = lambda trial: objective(trial, X, y, groups)\n","        study.optimize(func, n_trials=OPTUNA_TRIALS)\n","\n","        print(f\"[Optuna] Best Logloss: {study.best_value:.4f}\")\n","        print(f\"[Optuna] Best Params: {study.best_params}\")\n","        best_params = study.best_params\n","    elif MODE == 'Load':\n","        # Train with previous best hyperparameters\n","        best_params = {'n_estimators': 1455, 'learning_rate': 0.01581233636756958, 'max_depth': 4, 'min_child_weight': 8, 'gamma': 1.8554367882106972, 'subsample': 0.5178143107493339, 'colsample_bytree': 0.7705593029127545, 'reg_alpha': 0.15001414550285752, 'reg_lambda': 0.11106665752617169, 'scale_pos_weight': 1.5086109724471912}\n","        print(f\"\\n[Load] Load Previous Best Params: {best_params}\")\n","    else:\n","        raise ValueError(f'[Error] Invalid MODE (Must be \"Tune\" or \"Load\"): {MODE}')\n","\n","    ens_oof, ens_test = run_training(best_params, X, y, groups, X_test)\n","\n","    # Thresholding\n","    if MODE == 'Tune':\n","        best_t, best_f1 = find_best_threshold(y, ens_oof, step=0.001)\n","        print(f\"\\n[Post-Processing] OOF F1: {best_f1:.4f} (Thresh: {best_t:.3f})\")\n","    elif MODE == 'Load':\n","        best_t = 0.351\n","        print(f\"\\n[Post-Processing] Threshold will be override to {best_t}\")\n","    else:\n","        raise ValueError(f'[Error] Invalid MODE (Must be \"Tune\" or \"Load\"): {MODE}')\n","\n","    # Submission\n","    final_pred = (ens_test >= best_t).astype(int)\n","\n","    out = make_submission_df(sub, test, final_pred, ID_COL, TARGET_COL)\n","    out.to_csv(OUTPUT_PATH, index=False)\n","\n","    print(f\"\\n[Result] Saved: {OUTPUT_PATH}\")\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.9"}},"nbformat":4,"nbformat_minor":0}